@article{zheng_topological_2021-1,
 abstract = {Deep neural networks are known to have security issues. One particular threat is
the Trojan attack. It occurs when the attackers stealthily manipulate the model’s
behavior through Trojaned training samples, which can later be exploited. Guided
by basic neuroscientific principles, we discover subtle – yet critical – structural
deviation characterizing Trojaned models. In our analysis we use topological
tools. They allow us to model high-order dependencies in the networks, robustly
compare different networks, and localize structural abnormalities. One interesting
observation is that Trojaned models develop short-cuts from shallow to deep layers.
Inspired by these observations, we devise a strategy for robust detection of Trojaned
models. Compared to standard baselines it displays better performance on multiple
benchmarks.},
 author = {Zheng, Songzhu and Zhang, Yikai and Wagner, Hubert and Goswami, Mayank and Chen, Chao},
 date = {2021-06-11},
 journaltitle = {Neural Information Processing Systems},
 keywords = {1 - {AI} Security, 1 - Backdoor Attacks, 1 - Convolutional Neural Networks, 1 - Machine learning, 1 - Trojan Attack, 2 - Persistent homology:{RIps}, 3 - {NIST} trojai toolkit, 3 - Point cloud:High Dimension},
 title = {Topological Detection of Trojaned Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2021/file/8fd7f981e10b41330b618129afcaab2d-Paper.pdf}
}
